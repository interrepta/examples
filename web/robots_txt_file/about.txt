"Plik robots.txt pozwala kontrolować dostęp robotów do plików w Twojej witrynie. Plik robots.txt znajduje się w katalogu głównym witryny. W przypadku witryny www.example.com plik robots.txt znajduje się pod adresem www.example.com/robots.txt. Ma on format zwykłego tekstu i jest zgodny ze standardem Robots Exclusion Protocol. Plik robots.txt zawiera co najmniej 1 regułę. Każda reguła blokuje lub umożliwia dostęp określonego robota do wskazanego pliku w domenie lub subdomenie, w której jest przechowywany plik robots.txt. Domyślnie wszystkie pliki mogą być skanowane, o ile nie określisz inaczej w pliku robots.txt. "

"

Zasady dotyczące formatu i lokalizacji:

- Plik musi się nazywać robots.txt.
- Witryna może mieć tylko 1 plik robots.txt.
- Plik robots.txt musi się znajdować w katalogu głównym hosta witryny, do której się odnosi. Aby na przykład kontrolować indeksowanie wszystkich adresów URL witryny https://www.example.com/, plik robots.txt musi mieć lokalizację https://www.example.com/robots.txt. Nie można go umieścić w podkatalogu (na przykład https://example.com/pages/robots.txt). Jeśli nie wiesz, jak uzyskać dostęp do katalogu głównego witryny, lub potrzebujesz do tego uprawnień, skontaktuj się ze swoim dostawcą hostingu WWW. Jeśli nie masz dostępu do katalogu głównego witryny, możesz zablokować roboty w inny sposób, np. przy użyciu metatagów.
- Plik robots.txt może być publikowany w subdomenie (np. https://website.example.com/robots.txt) lub w portach niestandardowych (np. http://example.com:8181/robots.txt).
- Plik robots.txt dotyczy tylko ścieżek w ramach protokołu, hosta i portu, gdzie został opublikowany. Oznacza to, że reguły w pliku https://example.com/robots.txt będą mieć zastosowanie tylko do plików na https://example.com/, a nie do subdomen (takich jak https://m.example.com/) czy alternatywnych protokołów, takich jak http://example.com/.
- Plik robots.txt musi być plikiem tekstowym zakodowanym w formacie UTF-8 (który zawiera znaki ASCII). Google może ignorować znaki spoza zakresu UTF-8, przez co reguły w pliku robots.txt mogą być renderowane nieprawidłowo.


"

Źródło tekstu: https://developers.google.com/search/docs/crawling-indexing/robots/create-robots-txt
